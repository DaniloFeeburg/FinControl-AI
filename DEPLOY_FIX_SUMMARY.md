# üîß Corre√ß√£o do Erro de Deploy no Cloud Run

**Data:** 2025-12-29
**Problema:** Container falhava ao iniciar no Cloud Run com erro: "The user-provided container failed to start and listen on the port defined by PORT=8080"

---

## üìã Problemas Identificados

1. **‚ùå Falta flag `--port` no cloudbuild.yaml**
   - Cloud Run pode n√£o configurar corretamente o binding de porta sem especifica√ß√£o expl√≠cita
   - **Impacto:** Alta probabilidade de falha no binding da porta 8080

2. **‚ùå Aus√™ncia de tratamento de erros no entrypoint.sh**
   - Uvicorn podia falhar silenciosamente sem logs adequados
   - Timeout de health check muito curto (60 segundos)
   - **Impacto:** Dificuldade de diagn√≥stico + falhas silenciosas

3. **‚ùå Carregamento de m√≥dulos cr√≠tico no import**
   - `models.Base.metadata.create_all(bind=engine)` executava na linha 13 de [backend/main.py](backend/main.py#L13)
   - Qualquer falha de conex√£o ao banco durante import travava todo o Uvicorn
   - **Impacto:** Falha catastr√≥fica sem mensagens de erro claras

4. **‚ùå Health check inadequado**
   - Start period de 40s insuficiente para inicializa√ß√£o do banco
   - Endpoint `/` testado n√£o garantia que o backend estava funcionando
   - **Impacto:** Health check falhava antes da aplica√ß√£o estar pronta

5. **‚ùå Mensagens de erro gen√©ricas**
   - Database.py com mensagens simples n√£o ajudavam no diagn√≥stico
   - **Impacto:** Dif√≠cil identificar root cause em produ√ß√£o

---

## ‚úÖ Corre√ß√µes Aplicadas

### 1. **cloudbuild.yaml** - Configura√ß√£o de Porta e Performance
- ‚úÖ Adicionado `--port=8080` explicitamente (linha 34)
- ‚úÖ Adicionado `--startup-cpu-boost` para acelerar cold starts (linha 41)

### 2. **entrypoint.sh** - Tratamento Robusto de Erros
**Melhorias aplicadas:**
- ‚úÖ Verifica√ß√£o de vari√°veis cr√≠ticas (`DATABASE_URL`, `SECRET_KEY`) antes de iniciar
- ‚úÖ Valida√ß√£o de que o processo Uvicorn iniciou corretamente
- ‚úÖ Monitoramento cont√≠nuo do processo durante health check
- ‚úÖ Timeout aumentado de 60s ‚Üí 120s (60 tentativas √ó 2s)
- ‚úÖ Mensagens de erro detalhadas indicando poss√≠veis causas
- ‚úÖ Trap para graceful shutdown
- ‚úÖ Logs incrementais durante o wait loop

**C√≥digo adicionado:**
```bash
# Verifica√ß√£o antecipada de env vars
if [ -z "$DATABASE_URL" ]; then
    echo "ERROR: DATABASE_URL environment variable is not set!"
    exit 1
fi

# Verifica√ß√£o se processo iniciou
sleep 2
if ! kill -0 $BACKEND_PID 2>/dev/null; then
    echo "ERROR: FastAPI backend process failed to start"
    exit 1
fi

# Monitoramento durante health check
while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
    if ! kill -0 $BACKEND_PID 2>/dev/null; then
        echo "ERROR: Backend process died unexpectedly"
        exit 1
    fi
    # ... health check logic
done
```

### 3. **backend/main.py** - Inicializa√ß√£o Segura
**Mudan√ßa cr√≠tica:**
- ‚úÖ Movido `models.Base.metadata.create_all(bind=engine)` do n√≠vel de m√≥dulo (linha 13) para dentro do `lifespan` handler (linha 17)
- **Por qu√™?** Evita falhas de import se banco estiver lento ou indispon√≠vel temporariamente
- **Benef√≠cio:** Erros de conex√£o agora s√£o trat√°veis e geram logs do FastAPI

**Antes:**
```python
models.Base.metadata.create_all(bind=engine)  # ‚ùå No module level

@asynccontextmanager
async def lifespan(app: FastAPI):
    asyncio.create_task(start_scheduler_loop())
    yield
```

**Depois:**
```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    # ‚úÖ Inside lifespan - errors are caught and logged
    models.Base.metadata.create_all(bind=engine)
    asyncio.create_task(start_scheduler_loop())
    yield
```

### 4. **Dockerfile** - Health Check Otimizado
- ‚úÖ Start period: 40s ‚Üí 120s (permite inicializa√ß√£o completa do banco)
- ‚úÖ Endpoint alterado: `/` ‚Üí `/api/` (verifica que backend est√° respondendo)

**Antes:**
```dockerfile
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -f http://localhost:8080/ || exit 1
```

**Depois:**
```dockerfile
HEALTHCHECK --interval=30s --timeout=10s --start-period=120s --retries=3 \
    CMD curl -f http://localhost:8080/api/ || exit 1
```

### 5. **backend/database.py** - Mensagens de Erro Detalhadas
- ‚úÖ Mensagens de erro expandidas com instru√ß√µes de resolu√ß√£o
- ‚úÖ Adicionado `pool_pre_ping=True` para verificar conex√µes
- ‚úÖ Adicionado `pool_recycle=3600` para evitar conex√µes stale
- ‚úÖ Adicionado `connect_timeout=10` para falhar r√°pido em caso de problemas

**Melhorias:**
```python
try:
    engine = create_engine(
        SQLALCHEMY_DATABASE_URL,
        pool_pre_ping=True,      # ‚úÖ Verify connections before using
        pool_recycle=3600,       # ‚úÖ Recycle after 1 hour
        connect_args={"connect_timeout": 10}  # ‚úÖ Timeout fast
    )
except Exception as e:
    print("=" * 80)
    print("ERRO: Falha ao criar engine do banco de dados")
    print(f"Detalhes: {str(e)}")
    sys.exit(1)
```

---

## üöÄ Pr√≥ximos Passos para Deploy

### **Pr√©-requisitos no Google Cloud**

Antes de fazer o deploy, **CERTIFIQUE-SE** que as seguintes secrets existem no Google Cloud Secret Manager:

```bash
# 1. Verificar se as secrets existem
gcloud secrets list

# 2. Se n√£o existirem, criar:
gcloud secrets create DATABASE_URL --data-file=- <<< "postgresql://user:password@host:5432/database"
gcloud secrets create SECRET_KEY --data-file=- <<< "your-secret-key-here"
gcloud secrets create ALLOWED_ORIGINS --data-file=- <<< "https://your-domain.com"
gcloud secrets create GEMINI_API_KEY --data-file=- <<< "your-gemini-api-key"

# 3. Dar permiss√£o ao Cloud Run para acessar as secrets
gcloud secrets add-iam-policy-binding DATABASE_URL \
    --member="serviceAccount:PROJECT_NUMBER-compute@developer.gserviceaccount.com" \
    --role="roles/secretmanager.secretAccessor"

# Repetir para todas as secrets (SECRET_KEY, ALLOWED_ORIGINS, GEMINI_API_KEY)
```

**‚ö†Ô∏è IMPORTANTE:** Substitua `PROJECT_NUMBER` pelo n√∫mero do seu projeto GCP.

### **Deploy**

```bash
# Executar o Cloud Build (que far√° build + deploy)
gcloud builds submit --config cloudbuild.yaml

# OU fazer commit e push (se configurado CI/CD via GitHub)
git add .
git commit -m "Fix: Resolver erro de inicializa√ß√£o do container no Cloud Run"
git push origin main
```

### **Monitoramento do Deploy**

```bash
# 1. Acompanhar logs do Cloud Build
gcloud builds list --limit=5

# 2. Ap√≥s deploy, verificar logs do Cloud Run
gcloud run services logs tail fincontrol-ai --region=us-central1 --format=json

# 3. Verificar status do servi√ßo
gcloud run services describe fincontrol-ai --region=us-central1

# 4. Testar o endpoint
curl https://fincontrol-ai-HASH-uc.a.run.app/api/
# Deve retornar: {"message": "FinControl AI API is running"}
```

---

## üîç Diagn√≥stico de Falhas (Se Continuar Falhando)

### **Cen√°rio 1: Container n√£o inicia (exit imediatamente)**

**Verificar logs:**
```bash
gcloud run services logs read fincontrol-ai --region=us-central1 --limit=50
```

**Poss√≠veis causas:**
- ‚úÖ DATABASE_URL n√£o configurado ‚Üí Voc√™ ver√° "ERRO CR√çTICO: DATABASE_URL n√£o configurada"
- ‚úÖ Banco de dados inacess√≠vel ‚Üí Voc√™ ver√° "ERRO: Falha ao criar engine"
- ‚úÖ SECRET_KEY ausente ‚Üí Voc√™ ver√° "ERROR: SECRET_KEY environment variable is not set"

### **Cen√°rio 2: Container inicia mas health check falha**

**Verificar:**
```bash
# Logs em tempo real
gcloud run services logs tail fincontrol-ai --region=us-central1

# Buscar por mensagens espec√≠ficas:
# - "Step 1: Initializing database tables..." ‚úÖ
# - "Step 2: Starting FastAPI backend..." ‚úÖ
# - "Step 3: Waiting for backend..." ‚úÖ
# - "Step 4: Starting Nginx..." ‚úÖ
```

**Se travar em Step 3:**
- Backend n√£o est√° respondendo em http://127.0.0.1:8000
- Pode ser erro no c√≥digo Python (verificar traceback no log)
- Pode ser timeout de conex√£o ao banco (aumentar timeout)

### **Cen√°rio 3: Deploy OK mas retorna 502/503**

**Verificar:**
```bash
# Status da revis√£o
gcloud run revisions list --service=fincontrol-ai --region=us-central1

# Logs de requisi√ß√µes
gcloud run services logs read fincontrol-ai --region=us-central1 --limit=100 | grep -i error
```

**Poss√≠veis causas:**
- Nginx rodando mas backend morto (verificar logs do Uvicorn)
- Porta 8080 n√£o est√° sendo escutada (verificar Nginx config)

---

## üìä Resumo das Mudan√ßas

| Arquivo | Linhas Alteradas | Mudan√ßa Principal |
|---------|-----------------|-------------------|
| [cloudbuild.yaml](cloudbuild.yaml#L34) | 34, 41 | Adicionado `--port=8080` e `--startup-cpu-boost` |
| [entrypoint.sh](entrypoint.sh#L1-L106) | 1-106 | Reescrito completamente com tratamento robusto de erros |
| [backend/main.py](backend/main.py#L13-L21) | 13-21 | Movido `create_all` para lifespan |
| [Dockerfile](Dockerfile#L39-L42) | 39-42 | Health check: 40s‚Üí120s, endpoint `/`‚Üí`/api/` |
| [backend/database.py](backend/database.py#L10-L40) | 10-40 | Mensagens detalhadas + connection pooling |

---

## ‚ú® Melhorias de Performance Adicionadas

1. **Startup CPU Boost** - Cloud Run aloca mais CPU durante cold start
2. **Connection Pooling** - `pool_pre_ping` e `pool_recycle` para conex√µes saud√°veis
3. **Timeout Otimizado** - 120 segundos para inicializa√ß√£o completa
4. **Graceful Shutdown** - Trap para encerramento limpo de processos

---

## üìù Notas Finais

- **Backward Compatibility:** ‚úÖ Todas as mudan√ßas s√£o compat√≠veis com vers√µes anteriores
- **Ambiente Local:** ‚úÖ Funciona tanto localmente quanto no Cloud Run
- **Logs Melhorados:** ‚úÖ Agora √© poss√≠vel identificar exatamente onde falha
- **Seguran√ßa:** ‚úÖ Secrets continuam gerenciadas pelo Secret Manager

**Se o problema persistir ap√≥s estas corre√ß√µes, por favor forne√ßa:**
1. Output completo do `gcloud run services logs read`
2. Output do `gcloud builds list --limit=1 --format=json`
3. Confirma√ß√£o de que as 4 secrets est√£o criadas

---

**Documenta√ß√£o gerada automaticamente em 2025-12-29**
